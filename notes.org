* Code architecture notes for Arrow/Ivy implementation and benchmarks

** Algorithm implementations

From a node x a request gets sent towards node y which currently holds the token. The request message travels along this path, potentially being transformed during that. Nodes themselves could have arbitrary effects (like randomness or state) when they do an action.

So the essence is
- Send a request with some initial message state
- Forward a request in a node, potentially changing the request and the node's state
- Node holding the token receives the request, potentially changing the node's state

Of course, the algorithm's main goal is to select a node to use as the next predecessor (successor?). In order to have concurrency guarantees, it should only be allowed to reference previously traveled through nodes. If we were to choose integers as representations of nodes, we'd have a problem, because the algorithm could just create a new integer pointing to whatever node. We don't want the algorithm to rely on any such thing. So instead we use an abstract type ~i~, which you can't construct yourself, for the node indices. The only way you receive an ~i~ is by processing something on a node, in which case you get the ~i~ of the local node. You can send ~i~'s to the next predecessor as well. This way the algorithm only ever has access to the set of node indices ~i~ it the request traveled through already.

#+BEGIN_SRC haskell


  -- | Algorithm parametrized by the effects r it needs to run
  -- | Not parametrized by the message state, as this is internal to the algorithm
  -- | Base algorithm without node state, add state layer above that if needed. Stateless type:

  data Algorithm r = forall m . Algorithm
    { sendRequest
      :: forall i . i -- | Current node index
      -> Sem r (m i)
    , forwardRequest
      :: forall i . m i -- ^ Incoming message
      -> i -- ^ Current node index
      -> Sem r (i, m i) -- ^ Return the next predecessor and message
    , recvRequest
      :: forall i . m i -- ^ Incoming message
      -> i -- ^ Current node index
      -> Sem r i -- ^ Return the next predecessor
    }

  -- | What's sendRequest used for? Can do initialization on current node
  -- Can we combine forwardrequest and recvRequest? They both have the common thing of choosing an i

  -- | These three fields have almost the same type, the only difference is whether they have an incoming and outgoing message
  -- | Why (m a)? Because the message's state type m will probably want to pass along the current node somehow

#+END_SRC

*** State and weights

These should be implementable as a layer atop the standard algorithm. Maybe like this:

#+BEGIN_SRC haskell
  -- | Stateful: (TODO: Make more flexible, combine multiple)

  data StatefulAlgorithm r = forall n . StatefulAlgorithm
    { initialNodeState
      :: forall i . i
      -> Sem r (n i)
    , baseAlgorithm
      :: forall i . Algorithm (State (n i) ': r)
    }
  
  -- | Weights to all other nodes from some current node
  -- Indexed by i such that you can access the weight to a specific other node if you know its i, which can be sent along with messages
  type Weights i = i -> Double

  newtype WithWeights r = WithWeights
    { withoutWeights
      :: forall i .
      -> Algorithm (Reader (Weights i) ': r)
    }
#+END_SRC

TODO: The ~forall i~ won't work.

*** Arrow in this scheme

#+BEGIN_SRC haskell
  -- Equivalent to Identity
  newtype ArrowMessage i = ArrowMessage i

  arrow :: Algorithm r
  arrow = Algorithm
    { sendRequest = \myself ->
        return (ArrowMessage myself)
    , forwardRequest = \(ArrowMessage sender) myself ->
        return (sender, ArrowMessage myself)
    , recvRequest = \(ArrowMessage sender) myself ->
        return sender
    }

#+END_SRC

*** Ivy in this scheme

#+BEGIN_SRC haskell 
  -- Equivalent to Identity
  newtype IvyMessage i = IvyMessage i

  ivy :: Algorithm r
  ivy = Algorithm
    { sendRequest = \myself ->
        return (IvyMessage myself)
    , forwardRequest = \msg@(IvyMessage root) _ ->
        return (root, msg)
    , recvRequest = \msg@(IvyMessage root) _ ->
        return root
    }

#+END_SRC

*** Selected the node in the middle

#+BEGIN_SRC haskell
  newtype MiddleMessage a = MiddleMessage [a]

  middle :: Algorithm r
  middle = Algorithm
    { sendRequest = \myself ->
        return (MiddleMessage [myself])
    , forwardRequest = \(MiddleMessage nodes) myself ->
        return (nodes !! (length nodes `div` 2), MiddleMessage (myself : nodes))
    , recvRequest = \(MiddleMessage nodes) myself ->
        return (nodes !! (length nodes `div` 2))
    }
      
#+END_SRC

** Initial tree state

How do we determine the initial tree state?
- Matters a lot for Arrow
- Doesn't matter a lot for Ivy, the more request have happened the less part of the original tree is intact
- Both of which are instances of our algorithm spectrum, so there could be many more algorithms where initial tree state matters

So this should probably be part of the algorithm itself, because in any practical scenario, if you could choose the initial state, you might as well to get the best out of it.

Or even better: provide a set of algorithms and a set of initialization algorithms. Allow mix and matching them together.

*** Tree initialization algorithms

- Echo-algorithm to build a spanning tree from a specific root node
- Randomized
- Connect shortest edge, repeat until tree (and watch out for cycles)
- Tree with lowest diameter (how?)
- Tree that minimizes the summed distance between any pair of nodes (how?)

*** Tree convergence

Considering an algorithm that changes the tree state, one would think that the more requests are issued, the less the initial tree matters. But is that really true? We should plot how well a graph does over a number of requests (either by average request time or some average weight between all nodes). It seems that this graph should start at some high initial value for the initial tree, but converge to a fixed number the more requests are issued. Does it converge? Do different algorithms converge with different speeds.

** Running the algorithms

We need a way to represent the tree structure. How about having a mutable (ST) array with an entry holding the predecessor for every node.
#+BEGIN_SRC haskell
  data Node n = Node
    { successor :: Maybe Int -- ^ Nothing if holding token
    , state     :: n -- ^ Arbitrary state, chosen by the algorithm
    }

  -- | TODO: Split state into separate array for being able to not have any state at all


  -- | Mutable (ST) array's for keeping the state of all nodes
  -- Nodes 1, 2, 3 -> Array [(0, Nothing), (0, Just 0), (0, Just 1)]
  type GraphState s n = STUArray s Int (Node n)
#+END_SRC

Requests are just a sequence of integers of node indices. Weights should be stored in an immutable 2-dim UArray. One runST per request series.

Can we measure the competitive ratio by looping over the request sequence until the graph is in a state it already was? Will have to restrict to deterministic algorithms. https://en.wikipedia.org/wiki/Cycle_detection.


** Generating the requests

- Split graph into 2, choose a node from each side interleaved. More partitions?
- Completely randomly
- Randomly, but with a Pareto distribution, e.g. 80% of requests hit 20% of nodes. Realistic scenario.
- Random walk, preferably choosing next nodes that are near to the current one. 
- Always choose the furthest away node. Furthest away by either the direct weight from request to token, or by summing all weights on the path (which makes the sequence depend on the algorithm).
- Choose the node that hasn't been visited for the longest time. Interesting because only when the algorithm visits nodes it can influence them. Sequence depends on algorithm.

Make sure to seed random algorithms. Let's use the mwc-random package for random numbers, which seems to be one of the fastest. Can use Polysemy.Random to interpret randomness in it (maybe even works with the ST variants, which would be neat)


Can use something like pipes or conduits to generate these in a streaming fashion. What should the requests generator have access to? Potentially randomness, the weights, node indices.

** Generating the weights

- According to some underlying geometry, metric space
  - Ring
  - Grid/Torus
  - Fully connected
  - Clusters of nodes, intracluster fast, intercluster slow
  - Can add some jitter to all of these ^
- Mix weights up with some randomness, e.g. times a random number between 0.5 and 2
- Completely random weights
- Almost metric space, but add some wormholes here and there. Corresponds to expensive, extra fast wires in practice

* Parameters

- Initial tree state
- Algorithm
- Request sequence
- Graph weights
- (Metric)
